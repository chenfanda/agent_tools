{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fe53398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34f0536ec6024cb193d69f5bd56612a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/642 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2117163daf96415d96f3cbba4531e006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/mt5-large were not used when initializing MT5Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing MT5Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MT5Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef08a1c4cabc413997698936afb16274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/376 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4991d2607e094b42bdab06f32ac92fbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb9e01062084fdba068db5e4ba2b542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/oper/ch/env/py39/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:454: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "proxy_ip='http://127.0.0.1:7891'\n",
    "os.environ['https_proxy']=proxy_ip\n",
    "os.environ['http_proxy']=proxy_ip\n",
    "os.environ['HTTPS_PROXY']=proxy_ip\n",
    "os.environ['HTTP_PROXY']=proxy_ip\n",
    "\n",
    "\n",
    "from transformers import MT5Model, AutoTokenizer\n",
    "\n",
    "model = MT5Model.from_pretrained(\"google/mt5-large\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-large\")\n",
    "# article = \"UN Offizier sagt, dass weiter verhandelt werden muss in Syrien.\"\n",
    "# summary = \"Weiter Verhandlung in Syrien.\"\n",
    "# inputs = tokenizer(article, return_tensors=\"pt\")\n",
    "# labels = tokenizer(text_target=summary, return_tensors=\"pt\")\n",
    "\n",
    "# outputs = model(input_ids=inputs[\"input_ids\"], decoder_input_ids=labels[\"input_ids\"])\n",
    "# hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50091c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MT5Model, AutoTokenizer,MT5EncoderModel,MT5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d7240a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MT5ForConditionalGeneration.from_pretrained(\"google/mt5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25b294d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, MT5ForConditionalGeneration\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"mt5-small\")\n",
    "# model = MT5ForConditionalGeneration.from_pretrained(\"mt5-small\")\n",
    "\n",
    "# training\n",
    "input_ids = tokenizer(\"The <extra_id_0> walks in <extra_id_1> park\", return_tensors=\"pt\").input_ids\n",
    "labels = tokenizer(\"<extra_id_0> cute dog <extra_id_1> the <extra_id_2>\", return_tensors=\"pt\").input_ids\n",
    "outputs = model(input_ids=input_ids, labels=labels)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits\n",
    "\n",
    "# inference\n",
    "# input_ids = tokenizer(\n",
    "#     \"summarize: studies have shown that owning a dog is good for you\", return_tensors=\"pt\"\n",
    "# ).input_ids  # Batch size 1\n",
    "# outputs = model.generate(input_ids)\n",
    "# print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "# studies have shown that owning a dog is good for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "005b98dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 768])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.encoder_last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c938f745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<extra_id_0>'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(model.generate(tokenizer(\"你好\", return_tensors=\"pt\").input_ids)[0],skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f672909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=MT5EncoderModel.from_pretrained(\"google/mt5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaecda8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('/oper/ch/pretrain_model/mt5_large/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "debf5280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/oper/ch/pretrain_model/mt5_large/tokenizer_config.json',\n",
       " '/oper/ch/pretrain_model/mt5_large/special_tokens_map.json',\n",
       " '/oper/ch/pretrain_model/mt5_large/spiece.model',\n",
       " '/oper/ch/pretrain_model/mt5_large/added_tokens.json',\n",
       " '/oper/ch/pretrain_model/mt5_large/tokenizer.json')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained('/oper/ch/pretrain_model/mt5_large/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b83521e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm-6b\", trust_remote_code=True)\n",
    "# model = AutoModel.from_pretrained(\"THUDM/chatglm-6b\", trust_remote_code=True).half().cuda()\n",
    "# model = model.eval()\n",
    "# response, history = model.chat(tokenizer, \"你好\", history=[])\n",
    "# print(response)\n",
    "# response, history = model.chat(tokenizer, \"晚上睡不着应该怎么办\", history=history)\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c6b5cbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/, https://pypi.ngc.nvidia.com\n",
      "Collecting cpm_kernels\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/af/84/1831ce6ffa87b8fd4d9673c3595d0fc4e6631c0691eb43f406d3bf89b951/cpm_kernels-1.0.11-py3-none-any.whl (416 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m416.6/416.6 kB\u001b[0m \u001b[31m310.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: cpm_kernels\n",
      "Successfully installed cpm_kernels-1.0.11\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install cpm_kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098956e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
